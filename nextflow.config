params {
    hypToml = '/astro/mwaeor/cjordan/sdc3/sdc3.toml' // hyperdrive config file
    base = '/pawsey/mwa/mwaeor/dev/sdc3'
    uvfGlob = "/astro/mwaeor/dev/sdc3/uvf/ZW3_IFRQ_????.uvf"
    msGlob = "/astro/mwaeor/dev/sdc3/MS/ZW3_IFRQ_????.ms"
    storeDir = "/astro/mwaeor/dev/sdc3/store"
    // storeDir = 's3://sdc3.store'
    time_varying_station_beam = "/astro/mwaeor/dev/sdc3/Image/station_beam_time-varying.fits"
    station_beam = "/astro/mwaeor/dev/sdc3/Image/station_beam.fits"
    uniform_img_cube = "/astro/mwaeor/dev/sdc3/Image/ZW3.msw_image.fits"

    baseConfig = true // used to detect if a config file has not been applied.

    startFreqHz = 106e6 // Frequency of first channel [Hz]
    endFreqHz = 196e6 // Frequency of last channel [Hz]
    inWidthHz = 0.1e6 // with of each input channel
    intTime = 10 // integration time in seconds

    // ////// //
    // FILTER //
    // ////// //
    doFilter = true
    // filterFreqs = null // optional list of frequencies to filter on [Hz]
    // filterFreqs = (1060..1069).collect { it * 100000 }
    // filterTimes = (648..791) // 144 timesteps either side of lst0
    // timeblock and spw names are a function of spWidth and splitTime
    filterTimeblocks = null // optional list of timeblocks to filter on
    // filterTimeblocks = ["ts0720-0731"]
    // filterTimeblocks = ["ts0704-0735"]
    filterSpws = null // optional list of spectral windows to filter on
    // filterSpws = ["150MHz"]

    // //////////// //
    // SPLIT, MERGE //
    // //////////// //
    spWidthHz = -1 // width of merged spectral window, or -1 to use all
    // spWidthHz = 1e6
    splitTime = 12 // timesteps in merged files
    // splitTime = 32
    // splitTime = 144

    // ///////// //
    // CALIBRATE //
    // ///////// //
    doCal = false // toggle calibration
    hyp_dical_args = "--timesteps-per-timeblock 1 --max-iterations 300 --stop-thresh 1e-20"
    (calSuffix, calSrclist) = ["_cal-lobes", "/astro/mwaeor/dev/sdc3/catalog/sdc3_inner_lobes.fits"]
    hyp_sols_plot_args = ''

    // //////// //
    // SUBTRACT //
    // //////// //
    doSub = false // toggle subtraction
    // extra suffix to distinguish between subtractions
    // (subSuffix, subSrclist) = ["_sub-trecs", "/astro/mwaeor/cjordan/sdc3/sdc3_inner_lobes+trecs_rot-0.15_10.fits"]
    (subSuffix, subSrclist) = ["_sub-lobes", "/astro/mwaeor/dev/sdc3/catalog/sdc3_inner_lobes.fits"]

    // subSrclist = "/astro/mwaeor/software/LoBES/srclist_pumav3_EoR0LoBESv2_fixedEoR1pietro+ForA_phase1+2_edit.txt"
    // subSrclist = "/astro/mwaeor/dev/sdc3/catalog/LoBES_EoR0_27JAN2021_full.json"
    // subSrclist = "/astro/mwaeor/dev/sdc3/catalog/srclist_pumav3_EoR0LoBESv2_fixedEoR1pietro+ForA_phase1+2_AAAAAAA.fits"
    // subSrclist = "/astro/mwaeor/dev/sdc3/catalog/sdc3_inner_lobes.fits"

    // ///// //
    // IMAGE //
    // ///// //
    imgUnsub = false // toggle unsubtracted imaging
    imgModel = false // toggle calibration model imaging
    imgSub = true // toggle subtracted imaging
    // imgWidthHz = 15e6 // imaging bandwidth
    // imgCleanWidthHz = 1e6 // imaging bandwidth
    imgWidthHz = 1e6 // total imaging bandwidth
    imgCleanWidthHz = 0.1e6 // MFS imaging bandwidth
    // cli args for wsclean:
    imgSize = 2048 // image size in pixels
    imgScale = 16 // image pixel size in arcsec
    imgMinUV = null // minimum uv to image (lambdas)

    // only used in uniform imaging:
    imgTaperGaussian = 60 // taper gaussian used in uniform images
    imgAutoThreshold = 4 // auto threshold for multiscale clean
    imgNiter = 100000 // number of clean iterations
    wscleanSaveSrcs = true // save source list from wsclean
    wscleanMswExtra = "" // extra args for uniform

    // // just for testing
    // imgSize = 1024
    // imgScale = 1
    // imgNiter = 100

    wscleanCommon = "-reorder -use-wgridder -parallel-gridding 10 -oversampling 4095 -kernel-size 15 -nwlayers 1000 -grid-mode kb -taper-edge 100 -padding 2"
    wscleanMsn = "-weight natural -niter 0"
    wscleanMsw = "-weight uniform -no-update-model-required -multiscale -super-weight 4 -mgain 0.8"

    // ///////// //
    // MODELLING //
    // ///////// //
    beamThreshold = 0.1 // threshold for masking low beam values
    doAegean = false
    aeSeedClip = 5 // seed clip level (sigma)


    // //// //
    // GRID //
    // //// //
    doGrid = false
    // gridTime = 8 // number of timeblocks in each grid
    gridWidthHz = 15e6 // width of each grid
    // firstGpsTime = 1316268778
    gridMaxU = 600 // maximum uvw distance to grid
    gridNKBins = 80 // number of k bins to grid
    plotGrids = true // use --plotGrids=false to turn off all grid plots
    plotSingle1DDelta = true
    plotSingle2D = true

    // //////// //
    // SOFTWARE //
    // //////// //

    chipska_sif = "docker://d3vnull0/chipska:sdc3"
    hyperdrive_sif = "docker://d3vnull0/mwa_hyperdrive:sdc3-cuda11.4.3"
    mwa_qa_sif = 'docker://d3vnull0/mwa_qa:latest'
    casa_sif = 'docker://d3vnull0/casa:latest'
    wsclean_sif = 'docker://paulhancock/wsclean:2.10.0-build-1'
    ffmpeg_sif = 'docker://jrottenberg/ffmpeg:latest'

    hyperdrive = 'hyperdrive'
    casa = 'casa'
    wsclean = 'wsclean'

}

process {
    errorStrategy = 'ignore'
    afterScript = 'set -x; ls -alh'

    withLabel: python {
        module = 'singularity'
        container = "${params.mwa_qa_sif}"
    }
    withLabel: hyperdrive {
        // TODO: include https://github.com/cjordan/sdc3_vis_convert in hyperdrive docker img
        module = 'singularity'
        container = "${params.hyperdrive_sif}"
    }
    withLabel: casa {
        module = "singularity"
        container = "${params.casa_sif}"
    }
    withLabel: wsclean_hyp_casa {
        // TODO: make a docker image with hyperdrive, casa, and wsclean
        module = 'wsclean/2.9:hyperdrive/sdc3'
    }
    withLabel: mwa_reduce {
        module = 'singularity'
        container = "${params.mwa_reduce_sif}"
    }
    withLabel: python {
        module = 'singularity'
        container = "${params.mwa_qa_sif}"
    }
    withLabel: chipska {
        module = 'singularity'
        container = "${params.chipska_sif}"
    }
    withLabel: aegean {
        // TODO: make docker container from /astro/mwaeor/jline/tile_brad_21cm/create_tiled_models/garra_python.sif
        // which is basically https://github.com/PaulHancock/Aegean
        module = 'aegean:scipy'
    }
    withLabel: bane {
        // TODO: fix bane in aegean container
        // which is basically https://github.com/PaulHancock/Aegean
        // module = 'python:scipy:aegean'
        beforeScript = 'set -x; chown ${USER}:${PAWSEY_PROJECT} ${NXF_SCRATCH:="."}; chmod g+rs ${NXF_SCRATCH:="."}; module use /pawsey/mwa/software/python3/modulefiles; module use /astro/mwaeor/software/modulefiles; hostname; module load python scipy aegean'
    }
}

profiles {
    garrawarla {
        singularity {
            cacheDir = "/astro/${PAWSEY_PROJECT}/${USER}/singularity"
            runOptions = "--home \$PWD --cleanenv"
            enabled = true
            autoMounts = true
        }
        executor {
            $slurm {
                queueSize = 100
                jobName = { "nf-${task.process.split(':')[-1]}.${task.tag}" }
            }
        }
        params {
            // nvme_prelude = "chown ${USER}:${PAWSEY_PROJECT} ."
            // hyperdrive_prelude = "module use /pawsey/mwa/software/python3/modulefiles; module load hyperdrive/peel"
            // chips_prelude = "module use /pawsey/mwa/software/python3/modulefiles; module load chips/cmt"

            // sifs
            giant_squid_sif = '/pawsey/mwa/singularity/giant-squid/giant-squid_latest.sif'
            mwa_qa_sif = '/pawsey/mwa/singularity/mwa_qa/mwa_qa_latest.sif'
            // cotter_sif = '/pawsey/mwa/singularity/cotter/cotter_latest.sif'
            // casa_sif = '/pawsey/mwa/singularity/casa/casa.img'
            casa_sif = '/pawsey/mwa/singularity/casa5/casa5.sif'
            // wsclean_sif = '/pawsey/mwa/singularity/wsclean/wsclean.img'
            // ffmpeg_sif = '/pawsey/mwa/singularity/ffmpeg/ffmpeg_latest.sif'
            mwa_reduce_sif = '/pawsey/mwa/singularity/mwa-reduce/mwa-reduce.img'
            // imagemagick_sif = '/pawsey/mwa/singularity/imagemagick/imagemagick_latest.sif'
            // ssins_sif = '/pawsey/mwa/singularity/ssins/ssins_latest.sif'
            tap_sif = '/pawsey/mwa/singularity/tap/tap_latest.sif'
            mwax_mover_sif = '/pawsey/mwa/singularity/mwax_mover/mwax_mover_latest.sif'
            aegean_sif = '/astro/mwaeor/jline/tile_brad_21cm/create_tiled_models/garra_python.sif'


            // binaries
            singularity_prefix = '[ $(command -v singularity) ] || module load singularity; singularity exec --bind /astro --bind /pawsey'
            // hyperdrive = 'module use /pawsey/mwa/software/python3/modulefiles; module load hyperdrive; hyperdrive'
            giant_squid = "${params.singularity_prefix} ${params.giant_squid_sif} /opt/cargo/bin/giant-squid"
            jq = "/astro/mwaeor/dev/bin/jq"
            // wsclean = '${params.singularity_prefix} ${params.wsclean_sif} wsclean'
            casa = "${params.singularity_prefix} --bind \$PWD:/tmp --writable-tmpfs --pwd /tmp --home \$PWD --cleanenv ${params.casa_sif} casa"
            ps_metrics = '/pawsey/mwa/mwaeor/chips/bin/ps_metrics'
            mwa_reduce = "singularity exec -B /pawsey/mwa:/usr/lib/python3/dist-packages/mwapy/data ${params.mwa_reduce_sif}"

            // calibration
            // sourcelist = '/pawsey/mwa/software/python3/srclists/master/srclist_pumav3_EoR0LoBESv2_fixedEoR1pietro+ForA_phase1+2_edit.txt'
            sourcelist = '/pawsey/mwa/mwaeor/dev/srclists/srclist_pumav3_EoR0LoBESv2_fixedEoR1pietro+ForA_phase1+2_edit.txt'
            beam_path = '/pawsey/mwa/mwa_full_embedded_element_pattern.h5'
            img_mwa_path = '/pawsey/mwa'
        }
        process {
            executor = 'slurm'
            queue = 'workq'
            maxForks = 50
            cpus = 2
            memory = 60.GB // default: about 1/6 of a node
            time = 15.minute
            clusterOptions = { "--nodes=1 --cpus-per-task=${task.cpus} --account=${PAWSEY_PROJECT}" }
            scratch = 'ram-disk'
            stageInMode = 'copy'
            stageOutMode = 'move'
            beforeScript = 'set -x; chown ${USER}:${PAWSEY_PROJECT} ${NXF_SCRATCH:="."}; chmod g+rs ${NXF_SCRATCH:="."}; module use /pawsey/mwa/software/python3/modulefiles; module use /astro/mwaeor/software/modulefiles; hostname'
            // jobs which actually make use of multiprocessing
            withLabel: cpu_half {
                cpus = 18
            }
            // jobs which will need maximum cpu count
            withLabel: cpu_full {
                cpus = 36
            }
            // jobs which need a bit more memory
            withLabel: mem_half {
                memory = 180.GB
            }
            // jobs which will need maximum memory
            withLabel: mem_full {
                memory = 360.GB
            }
            // processes which handle big files that don't fit in ramdisk
            withLabel: nvme {
                scratch = "/nvmetmp/"
                clusterOptions = { "--nodes=1 --cpus-per-task=${task.cpus} --account=${PAWSEY_PROJECT} --tmp=440G" }
            }
            withLabel: nvme_full {
                scratch = "/nvmetmp/"
                clusterOptions = { "--nodes=1 --cpus-per-task=${task.cpus} --account=${PAWSEY_PROJECT} --tmp=880G" }
            }
            withLabel: gpu {
                queue = 'gpuq'
                clusterOptions = { "--nodes=1 --cpus-per-task=${task.cpus} --account=${PAWSEY_PROJECT}  --gres=gpu:1" }
            }
            withLabel: gpu_nvme {
                scratch = "/nvmetmp/"
                queue = 'gpuq'
                clusterOptions = { "--nodes=1 --cpus-per-task=${task.cpus} --account=${PAWSEY_PROJECT}  --gres=gpu:1 --tmp=440G" }
            }
            withLabel: datamover {
                scratch = 'ram-disk'
                stageInMode = "symlink"
                module = 'rclone/1.59.2'
                cpus = 1
                maxForks = 4
                memory = 8.GB
                time = 2.hour
                clusterOptions = { "--nodes=1 --cpus-per-task=${task.cpus} --account=${PAWSEY_PROJECT} --cluster=setonix" }
                queue = 'copy'
            }
            withLabel: rate_limit {
                maxForks = 5
            }
            withLabel: hyperdrive {
                module = 'hyperdrive/sdc3'
            }
            withLabel: aegean {
                module = 'singularity'
                container = "${params.aegean_sif}"
            }
        }
    }
}
